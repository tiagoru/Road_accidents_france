{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712d9d1c-1eeb-447d-bcfa-f5c3198b7713",
   "metadata": {},
   "source": [
    "# Modelling of France Accidents\n",
    "\n",
    "**Cohort:** mar23_accidents\n",
    "\n",
    "**Author:** Tobias Schulze\n",
    "\n",
    "**Date:** 30 Oktober 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6df835-aa14-4775-90df-de5512f881c4",
   "metadata": {},
   "source": [
    "## Loading of required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cfc8cd-2dd7-45e2-bd75-df68ef38c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import pickle\n",
    "import warnings\n",
    "import time\n",
    "import shap\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d12d86a-94ac-4349-b68f-2b8a40e21ebe",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aaa9044-2e16-4821-a259-0e2b8fd2b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/231030_clean_table_for_analysis.csv', low_memory = False, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552176c-9a85-4ead-ad23-1edfb5c1d448",
   "metadata": {},
   "source": [
    "## Data description\n",
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e361f45-f63c-48a3-bc60-777a1d287f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place</th>\n",
       "      <th>catu</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>an_nais</th>\n",
       "      <th>trajet</th>\n",
       "      <th>locp</th>\n",
       "      <th>an</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>...</th>\n",
       "      <th>manv</th>\n",
       "      <th>date</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>holiday</th>\n",
       "      <th>datetime</th>\n",
       "      <th>actp</th>\n",
       "      <th>num_veh</th>\n",
       "      <th>etatp</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Num_Acc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201900000001</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201900000001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1993</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201900000001</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201900000002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-30 02:50:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201900000003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-28 15:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              place  catu  grav  sexe  an_nais  trajet  locp    an  mois  \\\n",
       "Num_Acc                                                                    \n",
       "201900000001    2.0     2     4     2     2002     0.0  -1.0  2019    11   \n",
       "201900000001    1.0     1     4     2     1993     5.0  -1.0  2019    11   \n",
       "201900000001    1.0     1     1     1     1959     0.0  -1.0  2019    11   \n",
       "201900000002    1.0     1     4     2     1994     0.0  -1.0  2019    11   \n",
       "201900000003    1.0     1     1     1     1996     0.0  -1.0  2019    11   \n",
       "\n",
       "              jour  ...  manv        date  is_holiday  holiday  \\\n",
       "Num_Acc             ...                                          \n",
       "201900000001    30  ...  23.0  2019-11-30       False      NaN   \n",
       "201900000001    30  ...  23.0  2019-11-30       False      NaN   \n",
       "201900000001    30  ...  11.0  2019-11-30       False      NaN   \n",
       "201900000002    30  ...   0.0  2019-11-30       False      NaN   \n",
       "201900000003    28  ...   2.0  2019-11-28       False      NaN   \n",
       "\n",
       "                         datetime  actp  num_veh  etatp  day_of_week  \\\n",
       "Num_Acc                                                                \n",
       "201900000001  2019-11-30 01:30:00     0       14      0            5   \n",
       "201900000001  2019-11-30 01:30:00     0       14      0            5   \n",
       "201900000001  2019-11-30 01:30:00     0        0      0            5   \n",
       "201900000002  2019-11-30 02:50:00     0        0      0            5   \n",
       "201900000003  2019-11-28 15:15:00     1        0      0            3   \n",
       "\n",
       "              hour_of_day  \n",
       "Num_Acc                    \n",
       "201900000001            1  \n",
       "201900000001            1  \n",
       "201900000001            1  \n",
       "201900000002            2  \n",
       "201900000003           15  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fbf44b-f1ca-4d02-9b27-78827b41985d",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bb68a0-55d1-461b-87e2-72833557b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2421684 entries, 201900000001 to 201800055766\n",
      "Data columns (total 42 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   place        float64\n",
      " 1   catu         int64  \n",
      " 2   grav         int64  \n",
      " 3   sexe         int64  \n",
      " 4   an_nais      int64  \n",
      " 5   trajet       float64\n",
      " 6   locp         float64\n",
      " 7   an           int64  \n",
      " 8   mois         int64  \n",
      " 9   jour         int64  \n",
      " 10  hrmn         object \n",
      " 11  lum          int64  \n",
      " 12  agg          int64  \n",
      " 13  int          int64  \n",
      " 14  atm          float64\n",
      " 15  col          float64\n",
      " 16  dep          int64  \n",
      " 17  catr         float64\n",
      " 18  circ         float64\n",
      " 19  nbv          float64\n",
      " 20  vosp         float64\n",
      " 21  prof         float64\n",
      " 22  plan         float64\n",
      " 23  surf         float64\n",
      " 24  infra        float64\n",
      " 25  situ         float64\n",
      " 26  senc         float64\n",
      " 27  catv         int64  \n",
      " 28  occutc       float64\n",
      " 29  obs          float64\n",
      " 30  obsm         float64\n",
      " 31  choc         float64\n",
      " 32  manv         float64\n",
      " 33  date         object \n",
      " 34  is_holiday   bool   \n",
      " 35  holiday      object \n",
      " 36  datetime     object \n",
      " 37  actp         int64  \n",
      " 38  num_veh      int64  \n",
      " 39  etatp        int64  \n",
      " 40  day_of_week  int64  \n",
      " 41  hour_of_day  int64  \n",
      "dtypes: bool(1), float64(20), int64(17), object(4)\n",
      "memory usage: 778.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d258ad30-b0f4-4b86-9322-808ff955593e",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24315f42-0b75-439c-92a1-ed41d3b2c33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "place                0\n",
       "catu                 0\n",
       "grav                 0\n",
       "sexe                 0\n",
       "an_nais              0\n",
       "trajet               0\n",
       "locp                 0\n",
       "an                   0\n",
       "mois                 0\n",
       "jour                 0\n",
       "hrmn                 0\n",
       "lum                  0\n",
       "agg                  0\n",
       "int                  0\n",
       "atm                  0\n",
       "col                  0\n",
       "dep                  0\n",
       "catr                 0\n",
       "circ                 0\n",
       "nbv                  0\n",
       "vosp                 0\n",
       "prof                 0\n",
       "plan                 0\n",
       "surf                 0\n",
       "infra                0\n",
       "situ                 0\n",
       "senc                 0\n",
       "catv                 0\n",
       "occutc               0\n",
       "obs                  0\n",
       "obsm                 0\n",
       "choc                 0\n",
       "manv                 0\n",
       "date                 0\n",
       "is_holiday           0\n",
       "holiday        2367768\n",
       "datetime             0\n",
       "actp                 0\n",
       "num_veh              0\n",
       "etatp                0\n",
       "day_of_week          0\n",
       "hour_of_day          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54ae8d-7ed1-413e-81cf-04079aa3cec0",
   "metadata": {},
   "source": [
    "This data has no missing values, accept the `holiday` variable which contains the name of the holiday or NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee2b4b-2bca-4686-b48f-b0f0d43b4bed",
   "metadata": {},
   "source": [
    "### Drop variables\n",
    "The dataset contains still some variables that represent information represented by other variables or are a finer granulation. The latter might be added later, if the primary variable is relevant.\n",
    "\n",
    "- `holiday`: classifies the holiday, but will be used only, if `is_holiday` is relevant\n",
    "- `datetime`: was required to create other datetime variables\n",
    "- `hrmn`: was required to create time related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967aff4c-b3a7-4ea6-8e48-80a148b62871",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop = ['holiday', 'hrmn', 'datetime']\n",
    "\n",
    "df.drop(columns = columns_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50abfde-c053-45b5-a270-ae9adc390856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2421684 entries, 201900000001 to 201800055766\n",
      "Data columns (total 39 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   place        float64\n",
      " 1   catu         int64  \n",
      " 2   grav         int64  \n",
      " 3   sexe         int64  \n",
      " 4   an_nais      int64  \n",
      " 5   trajet       float64\n",
      " 6   locp         float64\n",
      " 7   an           int64  \n",
      " 8   mois         int64  \n",
      " 9   jour         int64  \n",
      " 10  lum          int64  \n",
      " 11  agg          int64  \n",
      " 12  int          int64  \n",
      " 13  atm          float64\n",
      " 14  col          float64\n",
      " 15  dep          int64  \n",
      " 16  catr         float64\n",
      " 17  circ         float64\n",
      " 18  nbv          float64\n",
      " 19  vosp         float64\n",
      " 20  prof         float64\n",
      " 21  plan         float64\n",
      " 22  surf         float64\n",
      " 23  infra        float64\n",
      " 24  situ         float64\n",
      " 25  senc         float64\n",
      " 26  catv         int64  \n",
      " 27  occutc       float64\n",
      " 28  obs          float64\n",
      " 29  obsm         float64\n",
      " 30  choc         float64\n",
      " 31  manv         float64\n",
      " 32  date         object \n",
      " 33  is_holiday   bool   \n",
      " 34  actp         int64  \n",
      " 35  num_veh      int64  \n",
      " 36  etatp        int64  \n",
      " 37  day_of_week  int64  \n",
      " 38  hour_of_day  int64  \n",
      "dtypes: bool(1), float64(20), int64(17), object(1)\n",
      "memory usage: 722.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e466b8d-e6d7-432a-bcd8-da9e0d60c3c5",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "### Encode or drop date variables\n",
    "The date and time variables are maybe important as grouping variables or as contrains for time dependent severity of accidents.\n",
    "\n",
    "_Problem_:\n",
    "\n",
    "Due to the export to `csv`, the `datatime` data time is lost and thus, it is required to assign it again.\n",
    "\n",
    "**Steps:**\n",
    "1. Fix `date` variable and transform to `integer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c175109c-ec79-4bf1-970a-7c6203b99538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(date = pd.to_datetime(df['date']))\n",
    "df['date'] = df.apply(lambda x: int(x['date'].timestamp()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab4df31-4a36-442f-a1d7-ed33b603dc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2421684 entries, 201900000001 to 201800055766\n",
      "Data columns (total 39 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   place        float64\n",
      " 1   catu         int64  \n",
      " 2   grav         int64  \n",
      " 3   sexe         int64  \n",
      " 4   an_nais      int64  \n",
      " 5   trajet       float64\n",
      " 6   locp         float64\n",
      " 7   an           int64  \n",
      " 8   mois         int64  \n",
      " 9   jour         int64  \n",
      " 10  lum          int64  \n",
      " 11  agg          int64  \n",
      " 12  int          int64  \n",
      " 13  atm          float64\n",
      " 14  col          float64\n",
      " 15  dep          int64  \n",
      " 16  catr         float64\n",
      " 17  circ         float64\n",
      " 18  nbv          float64\n",
      " 19  vosp         float64\n",
      " 20  prof         float64\n",
      " 21  plan         float64\n",
      " 22  surf         float64\n",
      " 23  infra        float64\n",
      " 24  situ         float64\n",
      " 25  senc         float64\n",
      " 26  catv         int64  \n",
      " 27  occutc       float64\n",
      " 28  obs          float64\n",
      " 29  obsm         float64\n",
      " 30  choc         float64\n",
      " 31  manv         float64\n",
      " 32  date         int64  \n",
      " 33  is_holiday   bool   \n",
      " 34  actp         int64  \n",
      " 35  num_veh      int64  \n",
      " 36  etatp        int64  \n",
      " 37  day_of_week  int64  \n",
      " 38  hour_of_day  int64  \n",
      "dtypes: bool(1), float64(20), int64(18)\n",
      "memory usage: 722.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712a786-07c6-4f26-94b5-640f756e2433",
   "metadata": {},
   "source": [
    "The correlation matrix shows some intervariable correlations, but no real importance of variables to predict the target `fatal`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fbf79-9a9a-40f3-844d-ebeb2bcb391d",
   "metadata": {},
   "source": [
    "#### Aggregation and encoding of the target variable\n",
    "In the previous notebook, we used the `grav` variable as is without any further processing. The modelling result was not satisfying. Therefore, it was decided to aggregate the four classes into two classes \"severe\" and \"non-severe\" encoded in `[1,0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad444593-3398-4cb7-9fa7-3e58ccd0dc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.grav.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972d0876-3174-4436-934d-67ee90d0ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "# grav encodes in 1=unscathed, 2=light injured, 3=hospitalized, 4=killed.\n",
    "# Thus [1,2] = 0, [3,4] = 1\n",
    "\n",
    "df['severe'] = np.where(df['grav'].isin([1, 2]), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75398e99-75d5-4188-b8e8-e2c7a28830a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.severe.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e8e7f-5fd1-4759-ba8f-49d0151662fd",
   "metadata": {},
   "source": [
    "The following visualisation shows the balance between the two classes. The dataset is much more balanced now compared to the four classes `grav`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7474412-4426-428f-99f9-d7487ad299d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAE6CAYAAADjtdOXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvDUlEQVR4nO3deVRV9eL+8eckcAABRwRUFCjULw5pOYSZOOKUQ2ZlqJnV/VmaQ16zyG5iedGolMrU9N7UMocG7VbmgJpYakWiOVsOKQ6IA5MTKuzfHy3P6oQDKLrPpvdrrb2W57P3Ofs5rLDHz/6cs22GYRgCAACwqNvMDgAAAHAjKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDNAKfDjjz/qgQceUI0aNWS32xUQEKDIyEj985//NDvaNcXFxclmszmNTZkyRbNmzSrxc9lststulStXLvFzAbh1bNzOALC2xYsXq1u3bmrVqpX+8Y9/KCgoSEeOHNHPP/+s+fPn6+DBg2ZHvKqDBw/q4MGDuueeexxj9erVU+XKlbV69eoSPZfNZlOvXr0KlTx3d3fdfffdJXouALcOZQawuKioKB06dEg7d+6Um5ub076CggLddptrTsCeOXNG3t7el913M8vM4MGDNXny5CI/5+zZs/Ly8irRHABKlmv+LQegyE6cOKHKlSsXKjKSLltkFixYoMjISJUtW1Y+Pj7q0KGDNm7c6NifmJgom82m3bt3F3ruCy+8IA8PDx0/ftwxtmLFCrVt21Z+fn7y9vbWvffeq5UrVzo979KlpNTUVPXq1UsVKlTQ7bff7rTvkpCQEG3btk3JycmOy0AhISE6deqUypcvr4EDBxbK9fvvv6tMmTJ64403ivATu7KQkBDdf//9WrhwoRo1aiRPT0+NHTtWkvTee++pZcuWqlKlisqWLav69esrISFBFy5ccHqNVq1aqV69ekpJSdF9990nb29vhYWFacKECSooKHA6NisrS//85z8VFhYmu92uKlWqqHPnztq5c6fjmPPnz2vcuHGqU6eO7Ha7/P39NWDAAB07duyG3itQmlBmAIuLjIzUjz/+qKFDh+rHH38s9D/XP4uPj9ejjz6qiIgIffLJJ/roo4+Um5ur++67T9u3b5ck9e3bVx4eHoXWrOTn52vOnDnq2rWrY43JnDlzFB0dLT8/P82ePVuffPKJKlasqA4dOhQqNJLUs2dP3XHHHfr00081bdq0y2ZctGiRwsLC1KhRI61fv17r16/XokWL5OPjoyeeeEIff/yxsrOznZ4zZcoUeXh46Iknnrjmz8swDF28eNFp+/MEdWpqqp5//nkNHTpUS5cu1YMPPihJ2rNnj2JiYvTRRx/p66+/1pNPPqk33njjsuUqPT1dffr0Ud++ffXll1+qU6dOio2N1Zw5cxzH5ObmqkWLFnr//fc1YMAAffXVV5o2bZpq1aqlI0eOSPpjZq179+6aMGGCYmJitHjxYk2YMEFJSUlq1aqVzp49e833C/wtGAAs7fjx40aLFi0MSYYkw93d3WjevLkxfvx4Izc313HcgQMHDDc3N2PIkCFOz8/NzTUCAwONhx9+2DHWs2dPo3r16kZ+fr5j7JtvvjEkGV999ZVhGIZx+vRpo2LFikbXrl2dXi8/P9+48847jaZNmzrGxowZY0gyXnnllUL5L+37s7p16xpRUVGFjt2zZ49x2223GZMmTXKMnT171qhUqZIxYMCAq/yU/nDpZ/TXbcaMGYZhGEbNmjWNMmXKGLt27brq6+Tn5xsXLlwwPvzwQ6NMmTLGyZMnHfuioqIMScaPP/7o9JyIiAijQ4cOjsevvvqqIclISkq64nnmzZtnSDI+//xzp/GUlBRDkjFlypRrvmfg74CZGcDiKlWqpO+++04pKSmaMGGCunfvrl9//VWxsbGqX7++45LQsmXLdPHiRT322GNOsxKenp6KiopyWp8yYMAAHTx4UCtWrHCMzZw5U4GBgerUqZMkad26dTp58qT69+/v9HoFBQXq2LGjUlJSdPr0aaesl2Y5rldYWJjuv/9+TZkyxTGbMnfuXJ04cULPPvtskV7j4YcfVkpKitPWo0cPx/4GDRqoVq1ahZ63ceNGdevWTZUqVVKZMmXk7u6uxx57TPn5+fr111+djg0MDFTTpk2dxho0aKD9+/c7Hi9ZskS1atVSu3btrpj166+/Vvny5dW1a1enn3HDhg0VGBhY4muKAKsqfJEdgCU1btxYjRs3liRduHBBL7zwgiZNmqSEhAQlJCTo6NGjkqQmTZpc9vl/Xl/TqVMnBQUFaebMmYqOjlZmZqa+/PJLDRs2TGXKlJEkx+v16tXriplOnjypsmXLOh4HBQXd2JuUNGzYMLVt21ZJSUmKjo7We++9p8jISN11111Fer6/v7/j53Q5l8t44MAB3Xfffapdu7befvtthYSEyNPTUz/99JMGDx5c6HJPpUqVCr2G3W53Ou7YsWOqUaPGVbMePXpUWVlZ8vDwuOz+P69dAv7OKDNAKeTu7q4xY8Zo0qRJ2rp1qyQ51rl89tlnqlmz5lWfX6ZMGfXr10/vvPOOsrKyNHfuXOXl5WnAgAGOYy693rvvvuv0seo/CwgIcHr81++TuR5t2rRRvXr1NHnyZPn4+Cg1NdVpLcqNulzGL774QqdPn9bChQudfnabNm267vP4+/tf82PzlStXVqVKlbR06dLL7vf19b3u8wOlCWUGsLgjR45cdjZhx44dkqSqVatKkjp06CA3Nzft2bOnSJd7BgwYoISEBM2bN0+zZs1SZGSk6tSp49h/7733qnz58tq+fXuRL/EU1V9nMf5q6NChevrpp5Wdna2AgAA99NBDJXr+v7pUcOx2u2PMMAzNmDHjul+zU6dOeuWVV7Rq1Sq1adPmssfcf//9mj9/vvLz89WsWbPrPhdQ2lFmAIvr0KGDqlevrq5du6pOnToqKCjQpk2b9NZbb8nHx0fDhg2T9MfHjl999VWNHj1ae/fuVceOHVWhQgUdPXpUP/30k8qWLev4GLIk1alTR5GRkRo/frzS0tI0ffp0p/P6+Pjo3XffVf/+/XXy5En16tVLVapU0bFjx/TLL7/o2LFjmjp16nW9p/r162v+/PlasGCBwsLC5Onpqfr16zv29+3bV7GxsVqzZo1efvnlK16GKSnt27eXh4eHHn30UY0aNUrnzp3T1KlTlZmZed2vOXz4cC1YsEDdu3fXiy++qKZNm+rs2bNKTk7W/fffr9atW6t37976+OOP1blzZw0bNkxNmzaVu7u7Dh48qG+//Vbdu3fXAw88UILvFLAos1cgA7gxCxYsMGJiYozw8HDDx8fHcHd3N2rUqGH069fP2L59e6Hjv/jiC6N169aGn5+fYbfbjZo1axq9evUyVqxYUejY6dOnG5IMLy8vIzs7+7LnT05ONrp06WJUrFjRcHd3N6pVq2Z06dLF+PTTTx3HXPrE0rFjxwo9/3KfZvr999+N6Ohow9fX15Bk1KxZs9DzHn/8ccPNzc04ePDgtX5EDpKMwYMHX3F/zZo1jS5dulx231dffWXceeedhqenp1GtWjXj+eefN5YsWWJIMr799lvHcVFRUUbdunULPb9///6F3kdmZqYxbNgwo0aNGoa7u7tRpUoVo0uXLsbOnTsdx1y4cMF48803Hef28fEx6tSpYwwcOND47bffivzegdKMbwAGYDnnz59XSEiIWrRooU8++cTsOABMxmUmAJZx7Ngx7dq1SzNnztTRo0f14osvmh0JgAugzACwjMWLF2vAgAEKCgrSlClTivxxbAClG5eZAACApfENwAAAwNIoMwAAwNJK/ZqZgoICHT58WL6+viXy7aMAAODmMwxDubm5qlq1qtPtVi6n1JeZw4cPKzg42OwYAADgOqSlpal69epXPabUl5lL9y5JS0uTn5+fyWkAAEBR5OTkKDg4uEj3ICv1ZebSpSU/Pz/KDAAAFlOUJSIsAAYAAJZGmQEAAJZGmQEAAJZGmQEAAJZGmQEAAJZW6j/N9HcW8uJisyPgFvp9QhezIwCAKZiZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlmZqmYmLi5PNZnPaAgMDHfsNw1BcXJyqVq0qLy8vtWrVStu2bTMxMQAAcDWmz8zUrVtXR44ccWxbtmxx7EtISNDEiRM1efJkpaSkKDAwUO3bt1dubq6JiQEAgCtxMz2Am5vTbMwlhmEoMTFRo0ePVs+ePSVJs2fPVkBAgObOnauBAwde9vXy8vKUl5fneJyTk3NzggMAAJdg+szMb7/9pqpVqyo0NFS9e/fW3r17JUn79u1Tenq6oqOjHcfa7XZFRUVp3bp1V3y98ePHq1y5co4tODj4pr8HAABgHlPLTLNmzfThhx9q2bJlmjFjhtLT09W8eXOdOHFC6enpkqSAgACn5wQEBDj2XU5sbKyys7MdW1pa2k19DwAAwFymXmbq1KmT48/169dXZGSkbr/9ds2ePVv33HOPJMlmszk9xzCMQmN/ZrfbZbfbb05gAADgcky/zPRnZcuWVf369fXbb7851tH8dRYmIyOj0GwNAAD4+3KpMpOXl6cdO3YoKChIoaGhCgwMVFJSkmP/+fPnlZycrObNm5uYEgAAuBJTLzONHDlSXbt2VY0aNZSRkaFx48YpJydH/fv3l81m0/DhwxUfH6/w8HCFh4crPj5e3t7eiomJMTM2AABwIaaWmYMHD+rRRx/V8ePH5e/vr3vuuUc//PCDatasKUkaNWqUzp49q0GDBikzM1PNmjXT8uXL5evra2ZsAADgQmyGYRhmh7iZcnJyVK5cOWVnZ8vPz8/sOLdUyIuLzY6AW+j3CV3MjgAAJaY4//92qTUzAAAAxUWZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlmbqvZkAANeH25X8vXC7kqtjZgYAAFgaZQYAAFgaZQYAAFgaZQYAAFgaZQYAAFgaZQYAAFiay5SZ8ePHy2azafjw4Y4xwzAUFxenqlWrysvLS61atdK2bdvMCwkAAFyOS5SZlJQUTZ8+XQ0aNHAaT0hI0MSJEzV58mSlpKQoMDBQ7du3V25urklJAQCAqzG9zJw6dUp9+vTRjBkzVKFCBce4YRhKTEzU6NGj1bNnT9WrV0+zZ8/WmTNnNHfuXBMTAwAAV2J6mRk8eLC6dOmidu3aOY3v27dP6enpio6OdozZ7XZFRUVp3bp1V3y9vLw85eTkOG0AAKD0MvV2BvPnz1dqaqpSUlIK7UtPT5ckBQQEOI0HBARo//79V3zN8ePHa+zYsSUbFAAAuCzTZmbS0tI0bNgwzZkzR56enlc8zmazOT02DKPQ2J/FxsYqOzvbsaWlpZVYZgAA4HpMm5nZsGGDMjIydPfddzvG8vPztWbNGk2ePFm7du2S9McMTVBQkOOYjIyMQrM1f2a322W3229ecAAA4FKue2bmyJEj6tWrl/z9/VWxYkV17dpVe/fuLfLz27Ztqy1btmjTpk2OrXHjxurTp482bdqksLAwBQYGKikpyfGc8+fPKzk5Wc2bN7/e2AAAoJS57pmZJ554Qs2aNdOrr76q8+fPa/LkyYqJidEPP/xQpOf7+vqqXr16TmNly5ZVpUqVHOPDhw9XfHy8wsPDFR4ervj4eHl7eysmJuZ6YwMAgFKmyGVm2LBhio+PV9myZSVJu3fv1sKFC+Xl5eXY37JlyxINN2rUKJ09e1aDBg1SZmammjVrpuXLl8vX17dEzwMAAKyryGWmWrVquvvuu5WQkKBu3brpkUceUbNmzdS5c2dduHBBCxcuVJ8+fW4ozOrVq50e22w2xcXFKS4u7oZeFwAAlF5FLjOjRo3SQw89pEGDBmnWrFl655131KxZM61evVr5+flKSEhQr169bmZWAACAQoq1ZiY0NFRLlizRnDlz1KpVKw0bNkxvvvnmVT8qDQAAcDMV+9NMJ06cUN++fZWSkqLU1FRFRkZq8+bNNyMbAADANRW5zHz77bcKDAyUv7+/qlevrp07d2rmzJmKj49X7969HYt1AQAAbqUil5lBgwbp+eef15kzZzR58mQNHz5cktSmTRtt3LhRbm5uatiw4U2KCQAAcHlFLjOHDx9Wly5d5OnpqY4dO+rYsWOOfXa7XfHx8Vq4cOFNCQkAAHAlRV4A3K1bN/Xq1UvdunXT999/r86dOxc6pm7duiUaDgAA4FqKPDPz3//+VwMHDlR2drb69u2rxMTEmxgLAACgaIo8M+Ph4aEhQ4bczCwAAADFdt03mgQAAHAFlBkAAGBplBkAAGBplBkAAGBpxS4zYWFhOnHiRKHxrKwshYWFlUgoAACAoip2mfn999+Vn59faDwvL0+HDh0qkVAAAABFVeSPZn/55ZeOPy9btkzlypVzPM7Pz9fKlSsVEhJSouEAAACupchlpkePHpIkm82m/v37O+1zd3dXSEiI3nrrrRINBwAAcC1FLjMFBQWSpNDQUKWkpKhy5co3LRQAAEBRFXvNzL59+0qsyEydOlUNGjSQn5+f/Pz8FBkZqSVLljj2G4ahuLg4Va1aVV5eXmrVqpW2bdtWIucGAAClQ5FnZv5s5cqVWrlypTIyMhwzNpd88MEHRX6d6tWra8KECbrjjjskSbNnz1b37t21ceNG1a1bVwkJCZo4caJmzZqlWrVqady4cWrfvr127dolX1/f64kOAABKmWLPzIwdO1bR0dFauXKljh8/rszMTKetOLp27arOnTurVq1aqlWrlv7973/Lx8dHP/zwgwzDUGJiokaPHq2ePXuqXr16mj17ts6cOaO5c+de8TXz8vKUk5PjtAEAgNKr2DMz06ZN06xZs9SvX78SDZKfn69PP/1Up0+fVmRkpPbt26f09HRFR0c7jrHb7YqKitK6des0cODAy77O+PHjNXbs2BLNBgAAXFexZ2bOnz+v5s2bl1iALVu2yMfHR3a7XU8//bQWLVqkiIgIpaenS5ICAgKcjg8ICHDsu5zY2FhlZ2c7trS0tBLLCgAAXE+xy8xTTz111cs8xVW7dm1t2rRJP/zwg5555hn1799f27dvd+y32WxOxxuGUWjsz+x2u2NB8aUNAACUXsW+zHTu3DlNnz5dK1asUIMGDeTu7u60f+LEicV6PQ8PD8cC4MaNGyslJUVvv/22XnjhBUlSenq6goKCHMdnZGQUmq0BAAB/X8UuM5s3b1bDhg0lSVu3bnXad7UZk6IyDEN5eXkKDQ1VYGCgkpKS1KhRI0l/XOJKTk7W66+/fsPnAQAApUOxy8y3335bYid/6aWX1KlTJwUHBys3N1fz58/X6tWrtXTpUtlsNg0fPlzx8fEKDw9XeHi44uPj5e3trZiYmBLLAAAArO26vmempBw9elT9+vXTkSNHVK5cOTVo0EBLly5V+/btJUmjRo3S2bNnNWjQIGVmZqpZs2Zavnw53zEDAAAcil1mWrdufdXLSatWrSrya/33v/+96n6bzaa4uDjFxcUV+TUBAMDfS7HLzKX1MpdcuHBBmzZt0tatWwvdgBIAAOBmK3aZmTRp0mXH4+LidOrUqRsOBAAAUBzF/p6ZK+nbt2+x7ssEAABQEkqszKxfv16enp4l9XIAAABFUuzLTD179nR6bBiGjhw5op9//ln/+te/SiwYAABAURS7zJQrV87p8W233abatWvr1VdfdbopJAAAwK1Q7DIzc+bMm5EDAADgulz3l+Zt2LBBO3bskM1mU0REhOOWAwAAALdSsctMRkaGevfurdWrV6t8+fIyDEPZ2dlq3bq15s+fL39//5uREwAA4LKK/WmmIUOGKCcnR9u2bdPJkyeVmZmprVu3KicnR0OHDr0ZGQEAAK6o2DMzS5cu1YoVK/R///d/jrGIiAi99957LAAGAAC3XLFnZgoKCuTu7l5o3N3dXQUFBSUSCgAAoKiKXWbatGmjYcOG6fDhw46xQ4cO6bnnnlPbtm1LNBwAAMC1FLvMTJ48Wbm5uQoJCdHtt9+uO+64Q6GhocrNzdW77757MzICAABcUbHXzAQHBys1NVVJSUnauXOnDMNQRESE2rVrdzPyAQAAXNV1f89M+/bt1b59+5LMAgAAUGxFvsy0atUqRUREKCcnp9C+7Oxs1a1bV999912JhgMAALiWIpeZxMRE/eMf/5Cfn1+hfeXKldPAgQM1ceLEYp18/PjxatKkiXx9fVWlShX16NFDu3btcjrGMAzFxcWpatWq8vLyUqtWrbRt27ZinQcAAJReRS4zv/zyizp27HjF/dHR0dqwYUOxTp6cnKzBgwfrhx9+UFJSki5evKjo6GidPn3acUxCQoImTpyoyZMnKyUlRYGBgWrfvr1yc3OLdS4AAFA6FXnNzNGjRy/7/TKOF3Jz07Fjx4p18qVLlzo9njlzpqpUqaINGzaoZcuWMgxDiYmJGj16tHr27ClJmj17tgICAjR37lwNHDiwWOcDAAClT5FnZqpVq6YtW7Zccf/mzZsVFBR0Q2Gys7MlSRUrVpQk7du3T+np6U7fLGy32xUVFaV169Zd9jXy8vKUk5PjtAEAgNKryGWmc+fOeuWVV3Tu3LlC+86ePasxY8bo/vvvv+4ghmFoxIgRatGiherVqydJSk9PlyQFBAQ4HRsQEODY91fjx49XuXLlHFtwcPB1ZwIAAK6vyJeZXn75ZS1cuFC1atXSs88+q9q1a8tms2nHjh167733lJ+fr9GjR193kGeffVabN2/W999/X2ifzWZzemwYRqGxS2JjYzVixAjH45ycHAoNAAClWJHLTEBAgNatW6dnnnlGsbGxMgxD0h9Fo0OHDpoyZUqhGZSiGjJkiL788kutWbNG1atXd4wHBgZK+mOG5s+XsDIyMq54LrvdLrvdfl05AACA9RTrS/Nq1qypb775RpmZmdq9e7cMw1B4eLgqVKhwXSc3DENDhgzRokWLtHr1aoWGhjrtDw0NVWBgoJKSktSoUSNJ0vnz55WcnKzXX3/9us4JAABKl+v6BuAKFSqoSZMmN3zywYMHa+7cufrf//4nX19fxzqYcuXKycvLSzabTcOHD1d8fLzCw8MVHh6u+Ph4eXt7KyYm5obPDwAArO+6b2dQEqZOnSpJatWqldP4zJkz9fjjj0uSRo0apbNnz2rQoEHKzMxUs2bNtHz5cvn6+t7itAAAwBWZWmYurbu5GpvNpri4OMXFxd38QAAAwHKK/NFsAAAAV0SZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlkaZAQAAlmZqmVmzZo26du2qqlWrymaz6YsvvnDabxiG4uLiVLVqVXl5ealVq1batm2bOWEBAIBLMrXMnD59WnfeeacmT5582f0JCQmaOHGiJk+erJSUFAUGBqp9+/bKzc29xUkBAICrcjPz5J06dVKnTp0uu88wDCUmJmr06NHq2bOnJGn27NkKCAjQ3LlzNXDgwFsZFQAAuCiXXTOzb98+paenKzo62jFmt9sVFRWldevWXfF5eXl5ysnJcdoAAEDp5bJlJj09XZIUEBDgNB4QEODYdznjx49XuXLlHFtwcPBNzQkAAMzlsmXmEpvN5vTYMIxCY38WGxur7Oxsx5aWlnazIwIAABOZumbmagIDAyX9MUMTFBTkGM/IyCg0W/Nndrtddrv9pucDAACuwWVnZkJDQxUYGKikpCTH2Pnz55WcnKzmzZubmAwAALgSU2dmTp06pd27dzse79u3T5s2bVLFihVVo0YNDR8+XPHx8QoPD1d4eLji4+Pl7e2tmJgYE1MDAABXYmqZ+fnnn9W6dWvH4xEjRkiS+vfvr1mzZmnUqFE6e/asBg0apMzMTDVr1kzLly+Xr6+vWZEBAICLMbXMtGrVSoZhXHG/zWZTXFyc4uLibl0oAABgKS67ZgYAAKAoKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSKDMAAMDSLFFmpkyZotDQUHl6euruu+/Wd999Z3YkAADgIly+zCxYsEDDhw/X6NGjtXHjRt13333q1KmTDhw4YHY0AADgAtzMDnAtEydO1JNPPqmnnnpKkpSYmKhly5Zp6tSpGj9+fKHj8/LylJeX53icnZ0tScrJybk1gV1IQd4ZsyPgFvo7/jf+d8bv99/L3/H3+9J7Ngzj2gcbLiwvL88oU6aMsXDhQqfxoUOHGi1btrzsc8aMGWNIYmNjY2NjYysFW1pa2jX7gkvPzBw/flz5+fkKCAhwGg8ICFB6evplnxMbG6sRI0Y4HhcUFOjkyZOqVKmSbDbbTc0L8+Xk5Cg4OFhpaWny8/MzOw6AEsTv99+LYRjKzc1V1apVr3msS5eZS/5aQgzDuGIxsdvtstvtTmPly5e/WdHgovz8/PjLDiil+P3++yhXrlyRjnPpBcCVK1dWmTJlCs3CZGRkFJqtAQAAf08uXWY8PDx09913KykpyWk8KSlJzZs3NykVAABwJS5/mWnEiBHq16+fGjdurMjISE2fPl0HDhzQ008/bXY0uCC73a4xY8YUutQIwPr4/caV2AyjKJ95MteUKVOUkJCgI0eOqF69epo0aZJatmxpdiwAAOACLFFmAAAArsSl18wAAABcC2UGAABYGmUGAABYGmUGAABYGmUGAABYGmUGpcKePXv08ssv69FHH1VGRoYkaenSpdq2bZvJyQAANxtlBpaXnJys+vXr68cff9TChQt16tQpSdLmzZs1ZswYk9MBuFFZWVn6z3/+o9jYWJ08eVKSlJqaqkOHDpmcDK6CMgPLe/HFFzVu3DglJSXJw8PDMd66dWutX7/exGQAbtTmzZtVq1Ytvf7663rzzTeVlZUlSVq0aJFiY2PNDQeXQZmB5W3ZskUPPPBAoXF/f3+dOHHChEQASsqIESP0+OOP67fffpOnp6djvFOnTlqzZo2JyeBKKDOwvPLly+vIkSOFxjdu3Khq1aqZkAhASUlJSdHAgQMLjVerVk3p6ekmJIIroszA8mJiYvTCCy8oPT1dNptNBQUFWrt2rUaOHKnHHnvM7HgAboCnp6dycnIKje/atUv+/v4mJIIr4t5MsLwLFy7o8ccf1/z582UYhtzc3JSfn6+YmBjNmjVLZcqUMTsigOv0//7f/9OxY8f0ySefqGLFitq8ebPKlCmjHj16qGXLlkpMTDQ7IlwAZQaWZhiGDhw4IH9/f6Wnpys1NVUFBQVq1KiRwsPDzY4H4Abl5OSoc+fO2rZtm3Jzc1W1alWlp6crMjJS33zzjcqWLWt2RLgAygwsraCgQJ6entq2bRvlBSjFVq1a5fjHyl133aV27dqZHQkuxM3sAMCNuO222xQeHq4TJ05QZoBS5uLFi/L09NSmTZvUpk0btWnTxuxIcFEsAIblJSQk6Pnnn9fWrVvNjgKgBLm5ualmzZrKz883OwpcHJeZYHkVKlTQmTNndPHiRXl4eMjLy8tp/6VvDAVgPTNnztSnn36qOXPmqGLFimbHgYuizMDyZs+efdX9/fv3v0VJAJS0Ro0aaffu3bpw4YJq1qxZaMFvamqqScngSlgzA8ujrAClV48ePcyOAAtgZgalwp49ezRz5kzt2bNHb7/9tqpUqaKlS5cqODhYdevWNTseAOAmYgEwLI+7ZgOlG3fNxrVQZmB53DUbKL24azaKgjIDy+Ou2UDpxV2zURSUGVged80GSi/umo2ioMzA8rhrNlB6cddsFAWfZoLlcddsoPTirtkoCsoMSo09e/Zo48aN3DUbKEW4azaKgjIDy0tOTlZUVJTZMQDcRNw1G1dDmYHleXh4KDAwUDExMerbt6/q1atndiQAJeT3339XSEiI2THg4lgADMs7fPiwRo0ape+++04NGjRQgwYNlJCQoIMHD5odDcANCgsLU4sWLfT+++9z01hcETMzKFX27dunuXPnat68edq5c6datmypVatWmR0LwHVKTU3VvHnzNH/+fB07dkwdOnRQ37591a1bN9ntdrPjwUVQZlDq5Ofna8mSJfrXv/6lzZs3Kz8/3+xIAG6QYRhavXq15s6dq88//1z5+fl68MEH9cEHH5gdDS6AMoNSY+3atfr444/12Wef6dy5c+rWrZv69OmjTp06mR0NQAlKTU3Vk08+yT9W4MCaGVjeSy+9pNDQULVp00b79+9XYmKi0tPTNWfOHIoMUEqkpaUpISFBDRs2VJMmTVS2bFlNnjzZ7FhwEczMwPKaN2+uPn366JFHHlHlypXNjgOgBE2fPl0ff/yx1q5dq9q1a6tPnz6KiYnhE05wQpkBALis4OBg9e7dW3369FHDhg3NjgMXRZlBqfDRRx9p2rRp2rdvn9avX6+aNWsqMTFRoaGh6t69u9nxAFwnwzBks9nMjgEXx5oZWN7UqVM1YsQIde7cWVlZWY4FgeXLl+e+LYDF2Ww2fffdd+rbt68iIyN16NAhSX/8A+b77783OR1cBWUGlvfuu+9qxowZGj16tNNNJRs3bqwtW7aYmAzAjfr888/VoUMHeXl5aePGjcrLy5Mk5ebmKj4+3uR0cBWUGVjevn371KhRo0Ljdrtdp0+fNiERgJIybtw4TZs2TTNmzJC7u7tjvHnz5kpNTTUxGVwJZQaWFxoaqk2bNhUaX7JkiSIiIm59IAAlZteuXWrZsmWhcT8/P2VlZd36QHBJbmYHAG7U888/r8GDB+vcuXMyDEM//fST5s2bp/Hjx+s///mP2fEA3ICgoCDt3r270Eexv//+e4WFhZkTCi6HMgPLGzBggC5evKhRo0bpzJkziomJUfXq1fX222+rd+/eZscDcAMGDhyoYcOG6YMPPpDNZtPhw4e1fv16jRw5Uq+88orZ8eAi+Gg2LO/s2bMyDEPe3t46fvy49u7dq7Vr1yoiIkIdOnQwOx6AGzR69GhNmjRJ586dk/THeriRI0fqtddeMzkZXAVlBpYXHR2tnj176umnn1ZWVpbq1Kkjd3d3HT9+XBMnTtQzzzxjdkQAN+jMmTPavn27CgoKFBERIR8fH7MjwYWwABiWl5qaqvvuu0+S9NlnnykgIED79+/Xhx9+qHfeecfkdABKgre3txo3bqw6depoxYoV2rFjh9mR4EIoM7C8M2fOyNfXV5K0fPly9ezZU7fddpvuuece7d+/3+R0AG7Eww8/7Lih5NmzZ9WkSRM9/PDDatCggT7//HOT08FVUGZgeXfccYe++OILpaWladmyZYqOjpYkZWRkyM/Pz+R0AG7EmjVrHDOvixYtUkFBgbKysvTOO+9o3LhxJqeDq6DMwPJeeeUVjRw5UiEhIWrWrJkiIyMl/TFLc7kv0wNgHdnZ2apYsaIkaenSpXrwwQfl7e2tLl266LfffjM5HVwFH82G5fXq1UstWrTQkSNHdOeddzrG27ZtqwceeMDEZABuVHBwsNavX6+KFStq6dKlmj9/viQpMzNTnp6eJqeDq6DMoFQIDAxUYGCg01jTpk1NSgOgpAwfPlx9+vSRj4+PatSooVatWkn64/JT/fr1zQ0Hl8FHswEALm3Dhg06cOCA2rdv7/hI9uLFi1W+fHnde++9JqeDK6DMAAAsYe3atWrcuLHsdrvZUeBiKDMAAEvw8/PTpk2buCcTCuHTTAAAS+Df3rgSygwAALA0ygwAwBLef/99BQQEmB0DLog1MwAAwNL4nhkAgMs6ffq0JkyYoJUrVyojI0MFBQVO+/fu3WtSMrgSygwAwGU99dRTSk5OVr9+/RQUFCSbzWZ2JLggLjMBAFxW+fLltXjxYr4cD1fFAmAAgMuqUKGC40aTwJVQZgAALuu1117TK6+8ojNnzpgdBS6My0wAAJfVqFEj7dmzR4ZhKCQkRO7u7k77U1NTTUoGV8ICYACAy+rRo4fZEWABzMwAAABLY2YGAODyNmzYoB07dshmsykiIkKNGjUyOxJcCGUGAOCyMjIy1Lt3b61evVrly5eXYRjKzs5W69atNX/+fPn7+5sdES6ATzMBAFzWkCFDlJOTo23btunkyZPKzMzU1q1blZOTo6FDh5odDy6CNTMAAJdVrlw5rVixQk2aNHEa/+mnnxQdHa2srCxzgsGlMDMDAHBZBQUFhT6OLUnu7u6F7tOEvy/KDADAZbVp00bDhg3T4cOHHWOHDh3Sc889p7Zt25qYDK6Ey0wAAJeVlpam7t27a+vWrQoODpbNZtP+/fvVoEEDffHFFwoODjY7IlwAZQYA4PJWrFihHTt2yDAMRUREqF27dmZHgguhzAAAXNrKlSu1cuVKZWRkFFon88EHH5iUCq6E75kBALissWPH6tVXX1Xjxo0VFBQkm81mdiS4IGZmAAAuKygoSAkJCerXr5/ZUeDC+DQTAMBlnT9/Xs2bNzc7BlwcZQYA4LKeeuopzZ071+wYcHGsmQEAuKxz585p+vTpWrFihRo0aFDoC/QmTpxoUjK4EtbMAABcVuvWra+4z2azadWqVbcwDVwVZQYAAFgaa2YAAIClUWYAAIClUWYAAIClUWYAAIClUWYAAIClUWYA3BKPP/64bDZboa1jx463LENcXJwaNmx4y84H4NbgS/MA3DIdO3bUzJkzncbsdrtJaQCUFszMALhl7Ha7AgMDnbYKFSro0UcfVe/evZ2OvXDhgipXruwoP4ZhKCEhQWFhYfLy8tKdd96pzz77zHH86tWrZbPZtHLlSjVu3Fje3t5q3ry5du3aJUmaNWuWxo4dq19++cUxKzRr1ixJf8zY1KhRQ3a7XVWrVtXQoUNvzQ8EQIlgZgaA6fr06aOHH35Yp06dko+PjyRp2bJlOn36tB588EFJ0ssvv6yFCxdq6tSpCg8P15o1a9S3b1/5+/srKirK8VqjR4/WW2+9JX9/fz399NN64okntHbtWj3yyCPaunWrli5dqhUrVkiSypUrp88++0yTJk3S/PnzVbduXaWnp+uXX3659T8EANeNMgPglvn6668dZeWSF154QS+++KLKli2rRYsWqV+/fpKkuXPnqmvXrvLz89Pp06c1ceJErVq1SpGRkZKksLAwff/993r//fedysy///1vx+MXX3xRXbp00blz5+Tl5SUfHx+5ubkpMDDQcfyBAwcUGBiodu3ayd3dXTVq1FDTpk1v9o8CQAmizAC4ZVq3bq2pU6c6jVWsWFHu7u566KGH9PHHH6tfv346ffq0/ve//znulrx9+3adO3dO7du3d3ru+fPn1ahRI6exBg0aOP4cFBQkScrIyFCNGjUum+mhhx5SYmKiwsLC1LFjR3Xu3Fldu3aVmxt/PQJWwW8rgFumbNmyuuOOOy67r0+fPoqKilJGRoaSkpLk6empTp06SZIKCgokSYsXL1a1atWcnvfXBcR/vquyzWZzev7lBAcHa9euXUpKStKKFSs0aNAgvfHGG0pOTi50h2YArokyA8AlNG/eXMHBwVqwYIGWLFmihx56SB4eHpKkiIgI2e12HThwwOmSUnF5eHgoPz+/0LiXl5e6deumbt26afDgwapTp462bNmiu+6667rPBeDWocwAuGXy8vKUnp7uNObm5qbKlSvLZrMpJiZG06ZN06+//qpvv/3WcYyvr69Gjhyp5557TgUFBWrRooVycnK0bt06+fj4qH///kU6f0hIiPbt26dNmzapevXq8vX11bx585Sfn69mzZrJ29tbH330kby8vFSzZs0Sfe8Abh7KDIBbZunSpY51LJfUrl1bO3fulPTHpab4+HjVrFlT9957r9Nxr732mqpUqaLx48dr7969Kl++vO666y699NJLRT7/gw8+qIULF6p169bKysrSzJkzVb58eU2YMEEjRoxQfn6+6tevr6+++kqVKlW68TcM4JawGYZhmB0CAADgevGleQAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNIoMwAAwNL+P4uyngeBwBt2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test if the \n",
    "import matplotlib.pyplot as plt\n",
    "# exploring severe cases in % \n",
    "event_counts = df['severe'].value_counts()\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(2,1,1)\n",
    "event_percentages.plot.bar()\n",
    "labels = ['severe','non-severe']\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_counts)), labels)\n",
    "plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Severity France')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170a409-e296-4cd0-8ee2-389c10869558",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data analysis\n",
    "### Correlation matrix\n",
    "To get a first glimpse on the possible contrains in the data, a correlation matrix is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b1e914-8e6f-42c6-a2cd-b4b63eb13c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort columns\n",
    "columns = df.columns.sort_values()\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b67e70-3b49-4e1c-94c0-963d7bdf042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "df_numeric_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ce130-1a33-4d1b-aff6-2b8d56591d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "correlation_matrix = df_numeric_scaled.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Generate the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Display the plot\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19180e-4918-4d1f-922a-14525d1a1c29",
   "metadata": {},
   "source": [
    "### Preparation of the training and test datasets\n",
    "#### Split data\n",
    "The dataset is split by year slides. We decided to drop the Covid-19 years 2020-21. The years 2005 to 2017 are selected for the train dataset and the years 2018 and 2019 for the test dataset. Furthermore, the `grav` variable is dropped because it is encoded in `severe`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91c8d87f-d44e-4eff-8c4d-26745cc8dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('grav', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac2bc919-2233-4813-840b-b7b0bd7b582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset to train and test data\n",
    "X_train = df.loc[df['an'] < 2018]\n",
    "X_train = X_train.drop('severe', axis = 1)\n",
    "\n",
    "X_test = df[(df['an'] >= 2018) & (df['an'] < 2020)]\n",
    "X_test = X_test.drop('severe', axis = 1)\n",
    "\n",
    "y_train = df['severe'].loc[df['an'] < 2018]\n",
    "y_test = df['severe'][(df['an'] >= 2018) & (df['an'] < 2020)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26625aa3-4aa4-407e-af35-fc4f79e5d944",
   "metadata": {},
   "source": [
    "#### Data scaling\n",
    "Decision trees are not sensitive to different scales and thus scaling is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935884d9-2884-4e18-a40e-2f6d6d4c6a93",
   "metadata": {},
   "source": [
    "### Modelling the data using a XGBoost Classification Model with Tree-based Parzen Estimators optimisation\n",
    "The Tree-based Parzen Estimator (TPE) [1] optimisation combines a Bayesian Sequential Model Based Optimisation (SMBO) and a random search on the hyperparemeter grid[2]. While the random search is a static approach, the SMBO optimises the model using prior runs to determine future points of exploration.\n",
    "\n",
    "The package `hyperopt` [4] is used for optimisation. The hyperparameter optimisation code is written based on ideas in [5]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899c3a5-71a0-4cc1-8b15-b8f860f89a90",
   "metadata": {},
   "source": [
    "#### The tuning space\n",
    "`hyperopt` uses a specific format of parameters expressions [7]. Hints on the parameter ranges are given in [1,5,7].\n",
    "\n",
    "The `booster` in this first model is `gbtree`. The evaluation metric is `logloss` or `auc`[8].\n",
    "\n",
    "Another classification method is Dropout with Multiple Additive Regression Trees (`dart`)[9], which is not used here.\n",
    "\n",
    "The metric used is `mlogloss` (as a special case of `logloss`). The reason is that `logloss` is an absolute measure of the quality of the classification, while `auc` is a simple ranking function [10]. `logloss` is discussed as better performing with imbalanced datasets [11].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85c2c349-31d2-4b9e-9573-1e69ce36b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tuning space\n",
    "booster = 'gbtree'\n",
    "eval_metric = 'logloss'\n",
    "\n",
    "tuning_space={\n",
    "    'eta': hp.uniform('eta', 0, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'gamma': hp.uniform ('gamma', 0, 10),\n",
    "    'reg_alpha' : hp.uniform('reg_alpha', 0, 100),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0, 10),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0, 1),\n",
    "    'colsample_bylevel' : hp.uniform('colsample_bylevel', 0, 1),\n",
    "    'colsample_bynode' : hp.uniform('colsample_bynode', 0, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "    'n_estimators': hp.quniform('n_estimators', 10, 1000, 1), # default is 100, so we try to check in the one magnitude space\n",
    "    'seed': 123,\n",
    "    'early_stopping_rounds': 10, # stop tuning early to avoid overfitting\n",
    "    'objective': 'binary:logistic',\n",
    "    'subsample': hp.uniform('subsample', 0, 1)\n",
    "    }\n",
    "\n",
    "tuning_space.update({'scale_pos_weight': hp.uniform('scale_pos_weight', 0, 2)}) # helps in auc\n",
    "tuning_space.update({'max_delta_step': hp.uniform('max_delta_step', 0, 2)}) # helps in auc\n",
    "tuning_space.update({'eval_metric': eval_metric})\n",
    "tuning_space.update({'booster': booster})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b7c6d-e438-43cc-8ec7-2adb7f2e57aa",
   "metadata": {},
   "source": [
    "#### The tuning function\n",
    "The following function integrates all steps required for the hyperoptimization tuning. The results are stored in the model and the tuning score is printed per step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "144da29f-81b6-4bb8-861c-b990c9c87a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the classification\n",
    "def hp_xgbclass(space, X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test):\n",
    "    \"\"\" Function for Bayesian hyperparameter optimisation of XGboost classification model.\n",
    "    Accepts a parameter `space` and the training and testing data set.\n",
    "        :param tuning_space: a catalog containing the parameters used for hyperparameter tuning, ranges given in hp objects\n",
    "        :param X_train: accepts the train data\n",
    "        :param X_test: accepts the test data\n",
    "        :param X_eval: accepts the eval data used for optimisation\n",
    "        :param y_train: accepts the train target\n",
    "        :param y_test: accepts the test target\n",
    "        :param y_eval: accepts the eval data used for optimisation\n",
    "    \"\"\"\n",
    "\n",
    "    clf=xgb.XGBClassifier(\n",
    "        eta = space['eta'],\n",
    "        eval_metric = space['eval_metric'],\n",
    "        booster = space['booster'],\n",
    "        n_estimators = np.int64(space['n_estimators']),\n",
    "        max_depth = np.int64(space['max_depth']),\n",
    "        gamma = space['gamma'],\n",
    "        reg_alpha = space['reg_alpha'],\n",
    "        min_child_weight=np.int64(space['min_child_weight']),\n",
    "        colsample_bytree=space['colsample_bytree'],\n",
    "        colsample_bylevel=space['colsample_bylevel'],\n",
    "        colsample_bynode=space['colsample_bynode'],\n",
    "        early_stopping_rounds = space['early_stopping_rounds'],\n",
    "        objective = space['objective'],\n",
    "        max_delta_step = space['max_delta_step'],\n",
    "        subsample = space['subsample']\n",
    "    )\n",
    "          \n",
    "    clf.fit(X_train,\n",
    "            y_train,\n",
    "            eval_set = [(X_test, y_test)],\n",
    "            verbose=False)\n",
    "        \n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred > 0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fbd217-11b2-477c-a7b3-0cd138977ef5",
   "metadata": {},
   "source": [
    "#### The tuning\n",
    "In this section, the hyperparameter tuning is performed. The results are stored in the trial db and the hyperparameter file for later re-use. In case, the downstream analysis is changed, the model could be loaded in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c54e61-8338-450f-9d02-8e932ed27244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.7826131846574776\n",
      "SCORE: 0.7663597050309146\n",
      "SCORE: 0.7775223073349138\n",
      "SCORE: 0.6739614729393264\n",
      "SCORE: 0.7806514893397346\n",
      "SCORE: 0.7668918248134603\n",
      "SCORE: 0.7365887945104299\n",
      "SCORE: 0.7642153417281186\n",
      "SCORE: 0.7797619756733897\n",
      "SCORE: 0.77778042513988\n",
      "SCORE: 0.774758461300199\n",
      "SCORE: 0.7782092978004392\n",
      "SCORE: 0.7808857808857809\n",
      "SCORE: 0.7761999499648563\n",
      "SCORE: 0.7777168884494268\n",
      "SCORE: 0.7690838406340962\n",
      "SCORE: 0.7619796444327961\n",
      "SCORE: 0.7817077868185194\n",
      "SCORE: 0.7832445805188565\n",
      "SCORE: 0.7556577437327011\n",
      "SCORE: 0.782764084297304\n",
      "SCORE: 0.7846185614499073\n",
      "SCORE: 0.7812868562442669\n",
      "SCORE: 0.7848885923843334\n",
      "SCORE: 0.7630955075588807\n",
      "SCORE: 0.78318898591471\n",
      "SCORE: 0.7845470826731474\n",
      "SCORE: 0.7836893373520291\n",
      "SCORE: 0.7044471712274097\n",
      "SCORE: 0.7687304177934502\n",
      "SCORE: 0.778864519920738\n",
      "SCORE: 0.78314133339687\n",
      "SCORE: 0.7596327579291804\n",
      "SCORE: 0.7848766792548735\n",
      "SCORE: 0.7852102468797528\n",
      "SCORE: 0.780472792397835\n",
      "SCORE: 0.7751436524860715\n",
      "SCORE: 0.7825814163122511\n",
      "SCORE: 0.7854643936415657\n",
      "SCORE: 0.7774786258602272\n",
      "SCORE: 0.7792814794518372\n",
      "SCORE: 0.7824186035429647\n",
      "SCORE: 0.7850553761967731\n",
      "SCORE: 0.7654423940624963\n",
      "SCORE: 0.765025434531397\n",
      "SCORE: 0.7756757722686173\n",
      "SCORE: 0.7838322949055487\n",
      "SCORE: 0.7813305377189534\n",
      "SCORE: 0.7742422256902666\n",
      "SCORE: 0.7813940744094066\n",
      "SCORE: 0.7792655952792239\n",
      "SCORE: 0.7857939902232918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (cv_rerun \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     19\u001b[0m     trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[0;32m---> 20\u001b[0m     best_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhp_xgbclass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtuning_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                            \u001b[49m\u001b[43malgo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# save the best parameters and the trials database\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file_trial, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m, in \u001b[0;36mhp_xgbclass\u001b[0;34m(space, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Function for Bayesian hyperparameter optimisation of XGboost classification model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mAccepts a parameter `space` and the training and testing data set.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    :param tuning_space: a catalog containing the parameters used for hyperparameter tuning, ranges given in hp objects\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    :param y_eval: accepts the eval data used for optimisation\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m clf\u001b[38;5;241m=\u001b[39mxgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[1;32m     15\u001b[0m     eta \u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m     eval_metric \u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_metric\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     subsample \u001b[38;5;241m=\u001b[39m space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     38\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running the crossvalidation or load stored parameters\n",
    "\n",
    "# lets check the run time\n",
    "start_time = time.monotonic()\n",
    "\n",
    "# Suppress warnings because of deprecated functions or parameters, we cannot influence\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Rerun (True) or get stored parameters (False)\n",
    "cv_rerun = True\n",
    "\n",
    "# define the stored files\n",
    "out_file_trial = './data/XGboost_model/231030_XGboost_gbtree_logloss_trial_db_severe.pkl'\n",
    "out_file_params = './data/XGboost_model/231030_XGboost_gbtree_logloss_hyperparameters_severe.pkl'\n",
    "\n",
    "\n",
    "# rerun the crossvalidation\n",
    "if (cv_rerun == True):\n",
    "    trials = Trials()\n",
    "    best_hyperparams = fmin(fn = hp_xgbclass,\n",
    "                            space = tuning_space,\n",
    "                            algo = tpe.suggest,\n",
    "                            max_evals = 100,\n",
    "                            trials = trials,\n",
    "                            verbose=0\n",
    "                           )\n",
    "    # save the best parameters and the trials database\n",
    "    with open(out_file_trial, 'wb') as f:\n",
    "        pickle.dump(trials, f)\n",
    "\n",
    "    with open(out_file_params, 'wb') as f:\n",
    "        pickle.dump(best_hyperparams, f)\n",
    "\n",
    "# get the stored hyperparameters\n",
    "else:\n",
    "    with open('./data/XGboost_model/231030_XGboost_gbtree_logloss_hyperparameters_severe.pkl', 'rb') as f:\n",
    "        best_hyperparams = pickle.load(f)\n",
    "\n",
    "# Track the end of the tuning\n",
    "end_time = time.monotonic()\n",
    "print(timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8684917-11ae-4664-819c-2d87f36c34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05242bdd-d2ca-4447-bf23-ec396d4b99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the run time\n",
    "start_time = time.monotonic()\n",
    "\n",
    "out_file_model = './data/XGboost_model/231030_XGboost_model_gbtree_logloss_severe.pkl'\n",
    "\n",
    "if(cv == True):\n",
    "    xgb_2 = xgb.XGBClassifier(\n",
    "        booster = tuning_space['booster'],\n",
    "        eta = best_hyperparams['eta'],\n",
    "        gamma = best_hyperparams['gamma'],\n",
    "        max_depth = np.int64(best_hyperparams['max_depth']),\n",
    "        min_child_weight = np.int64(best_hyperparams['min_child_weight']),\n",
    "        reg_alpha = best_hyperparams['reg_alpha'],\n",
    "        reg_lambda = best_hyperparams['reg_lambda'],\n",
    "        eval_metric = tuning_space['eval_metric'],\n",
    "        objective = tuning_space['objective'],\n",
    "        seed = tuning_space['seed'],\n",
    "        early_stopping_rounds = tuning_space['early_stopping_rounds'],\n",
    "        n_estimators = np.int64(best_hyperparams['n_estimators']),\n",
    "        subsample = best_hyperparams['subsample'],\n",
    "        max_delta_step = best_hyperparams['max_delta_step'],\n",
    "        colsample_bylevel = best_hyperparams['colsample_bylevel'],\n",
    "        colsample_bynode = best_hyperparams['colsample_bynode'],\n",
    "        colsample_bytree = best_hyperparams['colsample_bytree']\n",
    "    )\n",
    "      \n",
    "    xgb_2 = xgb_2.fit(X_train,\n",
    "              y_train,\n",
    "              eval_set = [(X_test, y_test)], \n",
    "              verbose = False)\n",
    "\n",
    "    # Dump the model for reuse\n",
    "    with open(out_file_model, 'wb') as f:\n",
    "        pickle.dump(xgb_2, f)\n",
    "\n",
    "else:\n",
    "    with open(out_file_model, 'rb') as f:\n",
    "        xgb_2 = pickle.load(f)\n",
    "\n",
    "# Track the end of the modelling\n",
    "end_time = time.monotonic()\n",
    "print(timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e9b563-5fcd-4744-adca-129cbf69342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_2.predict(X_test)\n",
    "y_pred = [round(value) for value in y_pred]\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "print(pd.crosstab(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee44902-9a6d-495b-a3cf-74eb43dc3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize = (5, 4))\n",
    "sns.set(font_scale=1)\n",
    "sns.heatmap(cm, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab1452-5565-44b2-9052-a3a15b8b15a6",
   "metadata": {},
   "source": [
    "#### Variable importance and interpretation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57abeed0-baf2-452e-a69f-7ca3cd3a5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_2, max_num_features=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1bb75-aab4-490e-bf01-651fea18c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the run time\n",
    "start_time = time.monotonic()\n",
    "\n",
    "thresholds = np.sort(xgb_2.feature_importances_)\n",
    "for thresh in thresholds:\n",
    " # select features using threshold\n",
    " selection = SelectFromModel(xgb_2, threshold=thresh, prefit=True)\n",
    " select_X_train = selection.transform(X_train)\n",
    " # train model\n",
    " selection_model = xgb.XGBClassifier()\n",
    " selection_model.fit(select_X_train, y_train)\n",
    " # eval model\n",
    " select_X_test = selection.transform(X_test)\n",
    " y_pred = selection_model.predict(select_X_test)\n",
    " predictions = [round(value) for value in y_pred]\n",
    " accuracy = accuracy_score(y_test, predictions)\n",
    " print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "# Track the end of the modelling\n",
    "end_time = time.monotonic()\n",
    "print(timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f5ede-f3e8-4a59-a32e-c0edd3c5e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the run time\n",
    "start_time = time.monotonic()\n",
    "\n",
    "# compute the SHAP values for the linear model\n",
    "explainer = shap.Explainer(xgb_2)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Track the end of the shap modelling\n",
    "end_time = time.monotonic()\n",
    "print(timedelta(seconds=end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ad9e9-0ba3-474f-887d-8a73751fb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarize the effects of features\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27dd7a-5f70-4b36-a89a-7f4df03305e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.force_plot(explainer.expected_value, shap_values[0], feature_names = explainer.feature_names)\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[0, :], X_train.iloc[0, :], matplotlib = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbbc29-ac38-44b6-ac91-1a5ef991afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.force_plot(explainer.expected_value, shap_values[0], feature_names = explainer.feature_names)\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[1, :], X_train.iloc[0, :], matplotlib = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79fcfa86-14d9-4351-a598-18d1563f3c7c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "format = 'svg' #You should try the 'svg'\n",
    "\n",
    "image = xgb.to_graphviz(xgb_1, num_trees=0, rankdir='TB')\n",
    "\n",
    "#Set a different dpi (work only if format == 'png')\n",
    "image.graph_attr = {'dpi':'400'}\n",
    "\n",
    "image.render('231022_XGBoost_Tree_severity', format = format)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aef1fc-ee62-4552-92ab-7710fe24b9f1",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] [Bergstra, J., Yamins, D., Cox, D. D. (2013) Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures. TProc. of the 30th International Conference on Machine Learning (ICML 2013), June 2013, pp. I-115 to I-23.](https://proceedings.neurips.cc/paper_files/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)\n",
    "\n",
    "[2] https://towardsdatascience.com/hyperopt-demystified-3e14006eb6fa\n",
    "\n",
    "[3] https://xgboost.readthedocs.io/en/stable/tutorials/categorical.html\n",
    "\n",
    "[4] https://github.com/hyperopt/hyperopt\n",
    "\n",
    "[5] https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "\n",
    "[6] https://github.com/hyperopt/hyperopt/wiki/FMin\n",
    "\n",
    "[7] https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "\n",
    "[8] https://www.datamachines.io/blog/auc-vs-log-loss\n",
    "\n",
    "[9] [Rashmi, K.V., Gilad-Bachrach (2015) DART: Dropouts meet Multiple Additive Regression Trees. arXiv:1505.01866v](https://doi.org/10.48550/arXiv.1505.01866)\n",
    "\n",
    "[10] https://datamachines.com/blog/auc-vs-log-loss\n",
    "\n",
    "[11] https://stats.stackexchange.com/questions/322408/logloss-vs-gini-auc\n",
    "\n",
    "[12] https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
