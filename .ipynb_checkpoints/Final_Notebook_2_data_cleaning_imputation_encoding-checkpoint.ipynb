{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714ee55f-d623-4cbd-9e04-e706d92bd463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import holidays\n",
    "from datetime import datetime\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ed9217-75e8-4c3d-b161-fc638bd9330f",
   "metadata": {},
   "source": [
    "# Data cleaning, imputation, and encoding\n",
    "\n",
    "\n",
    "**Authors:** Tobias Schulze, Tiago Russomano, Johanna StÃ¤rkl\n",
    "\n",
    "**Last update:** 16 October 2023\n",
    "\n",
    "All imported files were preprocessed to standardize file name schemes and separators.\n",
    "\n",
    "In general, issues occurring during import and data type conversion was fixed on the fly.\n",
    "\n",
    "Further curation will be performed after in deep evaluation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20c790-2fa2-425b-a857-238bde1f21bb",
   "metadata": {},
   "source": [
    "## Goals of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0192d384-0983-43d7-8c88-0f5f89c39543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/231018_merged_tables_basic_data.csv', low_memory=False, header = 0, index_col=0, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b9703d-9ed4-434d-9bce-e00d746da917",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# store date in string format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43man\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmois\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjour\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/frame.py:10037\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10025\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10027\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10028\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10029\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10035\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10036\u001b[0m )\n\u001b[0;32m> 10037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/apply.py:977\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m    979\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/apply.py:1085\u001b[0m, in \u001b[0;36mFrameColumnApply.series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mseries_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1085\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m   1086\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/apply.py:802\u001b[0m, in \u001b[0;36mFrameApply.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/frame.py:12284\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  12210\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m  12211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m  12212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  12213\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  12214\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12282\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  12283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 12284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/internals/managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/internals/managers.py:1697\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m   1696\u001b[0m     rl \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mmgr_locs\n\u001b[0;32m-> 1697\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1698\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1699\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/mli-project/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2247\u001b[0m, in \u001b[0;36mNumpyBlock.get_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: DtypeObj \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[0;32m-> 2247\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_dtype_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# store date in string format\n",
    "df['date'] = df.apply(lambda row: datetime(row['an'], row['mois'], row['jour']).strftime('%Y-%m-%d'), axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97f15e-92ff-49bb-9aaa-a16757d6550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60171092-04b0-4c3b-a9b4-ed55492d17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4664f-b6b3-4b12-ab88-3fc9c294b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get holiday list for France\n",
    "fr_holidays = holidays.FR()\n",
    "df['is_holiday'] = df.apply(lambda row: row['date'] in fr_holidays, axis = 1)\n",
    "df['holiday'] = df.apply(lambda row: fr_holidays.get(row['date']) if row['is_holiday'] == True else np.nan, axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a73ca-eb5f-4142-a4cd-6d0a36e668be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['holiday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1601a4-cc18-40fa-9d91-13224bee3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate missing values of each colum\n",
    "percent_missing = round(df.isnull().sum() * 100 / len(df), 1)\n",
    "missing_value_df = pd.DataFrame({'column_name': df.columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "percent_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0336f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of the missing percentages values of each colum\n",
    "plt.figure(figsize=(10, 6))\n",
    "percent_missing.plot(kind='bar')\n",
    "plt.title('Percentage of Missing Values by Columns')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing Percentage %')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd8468-7846-457d-a089-4c9cea43aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning of the dataset regarding missing values\n",
    "\n",
    "#delete columns id_vehicule, com, gps, voie, v1, v2, pr, pr1, lartpc, larrout, vma, env1, motor, secu1, \n",
    "#secu2, secu3, secu\n",
    "\n",
    "df.drop(['id_vehicule', 'com', 'gps', 'voie', 'v1', 'v2',\n",
    "         'pr', 'pr1', 'lartpc', 'larrout', 'vma', 'env1', 'motor', \n",
    "         'secu', 'secu1', 'secu2', 'secu3'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d76f07-4200-4bdf-94eb-a2c970aa2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaN with -1 (coded as no information) in columns\n",
    "#place, an_nais, trajet, locp, actp, etatp ,atm, col, circ, nbv, vosp, prof, plan, surf, infra\n",
    "#situ, senc, occutc, obs, obsm, choc, manv\n",
    "\n",
    "df.fillna({'place':-1, 'an_nais':-1, 'trajet':-1, 'locp':-1, 'actp': -1,\n",
    "           'etatp':-1, 'atm':-1, 'col':-1, 'circ':-1, \n",
    "           'nbv':-1, 'vosp':-1, 'prof':-1, 'plan': -1, \n",
    "           'surf':-1, 'infra':-1, 'situ': -1, 'senc':-1, 'occutc':-1, \n",
    "           'obs': -1, 'obsm': -1, 'choc':-1, 'manv':-1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b4ca9-390c-45be-80bc-2223b9e101ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove lines with NaN in column catr\n",
    "\n",
    "df.dropna(subset=['catr'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059365a-167d-4bb1-93d8-dca178f01d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform date to datetime\n",
    "df['date'] =  pd.to_datetime(df['date'], format=\"%Y-%m-%d\")\n",
    "\n",
    "df['date'] = df['date'].dt.date\n",
    "\n",
    "df['date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac27c4e-078b-4a80-8387-5d1a2ebdc448",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_clean = round(df.isnull().sum() * 100 / len(df), 1)\n",
    "percent_missing_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cbc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of the missing percentages values of each colum\n",
    "plt.figure(figsize=(10, 6))\n",
    "percent_missing_clean.plot(kind='bar')\n",
    "plt.title('Percentage of Missing Values by Columns after cleanning')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing Percentage %')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc14e14-dd2e-40a8-8be5-a60c60cce3a0",
   "metadata": {},
   "source": [
    "## Transform data types\n",
    "### Date and time variables\n",
    "The date and time variables are maybe important as grouping variables or as contrains for time dependent severity of accidents.\n",
    "\n",
    "For the grouping, a timestamp is required for unbiased identification time related accidents.\n",
    "\n",
    "_Problem_:\n",
    "\n",
    "During the transformation of the `hrmn` variable, I got aware, that the string contain integers like `1`,  `801`, or `1300`. Hence, anytime during data conversion, the colon got lost and the values got truncated. Hence `1` should be `00:01` and so on. Therefore, we need an additional transformation of the truncated data to `hh:mm` format.\n",
    "\n",
    "**Steps:**\n",
    "1. Fixing the truncated values in `hrmn`\n",
    "\n",
    "~~3. Creation of a `datatime` variable in format y-m-d hh:mm~~\n",
    "\n",
    "~~4. Transformation of the datatime varible to a `timestamp` variable~~\n",
    "\n",
    "\n",
    "In addition, we need to transform the type of `an_nais` to integer and `date` to `date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4cad4-2b0c-4fe3-ab78-eb583d317c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the hrmn issue:\n",
    "# Remove the colon\n",
    "df['hrmn'] = df.apply(lambda x: re.sub(string=x['hrmn'], pattern=':', repl=''), axis = 1)\n",
    "\n",
    "# Pad the string to four zeros\n",
    "df['hrmn'] = df.apply(lambda x: x['hrmn'].zfill(4), axis = 1)\n",
    "\n",
    "# Transform the variable to 'hh:mm' and split to hours and minutes\n",
    "df = df.assign(hrmn = pd.to_datetime(df['hrmn'], format='%H%M').dt.strftime('%H:%M'))\n",
    "\n",
    "# Create the daytime variable\n",
    "df['datetime'] = df.apply(lambda x: datetime(x['an'], x['mois'], x['jour'], datetime.strptime(x['hrmn'], \"%H:%M\").hour, datetime.strptime(x['hrmn'], \"%H:%M\").minute), axis = 1)\n",
    "\n",
    "# Create the timestamp\n",
    "#df['timestamp'] = df.apply(lambda x: datetime.timestamp(x['datetime']), axis = 1)\n",
    "\n",
    "# Transform `an_nais`\n",
    "df['an_nais'] = df['an_nais'].astype('int64')\n",
    "\n",
    "\n",
    "### this is not working \n",
    "# Transform `date`\n",
    "#df = df.assign(date = pd.to_datetime(df['date'], format='mixed'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bcd69f-4000-41ec-b648-2164cdbcd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hrmn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5923531c",
   "metadata": {},
   "source": [
    "## Exploring the data before filtering the target region and target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the types of accidents in France all regions\n",
    "event_counts = df['grav'].value_counts()\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(2,1,1)\n",
    "event_percentages.plot.bar()\n",
    "labels = ['unscathed','Killed','Hospitalized','light injury','unknow']\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Percentage of accident gravity per types in France (all regions)')\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# exploring the types of accidents in France all regions\n",
    "event_counts = df['grav'].value_counts()\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(2,1,1)\n",
    "event_percentages.plot.bar()\n",
    "#labels = ['unscathed','Killed','Hospitalized','light injury','unknow']\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)))#, labels)\n",
    "plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Percentage of accident gravity per types in France (all regions)')\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ce044e-02fb-477d-b326-6f053773df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.grav.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a1318-6351-430c-9549-e58c127fe77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explroring the number of acidents with fatal victims \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot for Severe Cases\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='an', data=df[df['grav'] == 4], palette='viridis')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of fatal Cases')\n",
    "plt.title('Number of fatal Cases (grav=4) per Year')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc03fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring variables that might contribute to the accidents \n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#agglomeration\n",
    "event_counts = df['agg'].value_counts()\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.tight_layout(w_pad=3.0)\n",
    "event_percentages.plot.bar()\n",
    "labels = ['Out of agglomeration', 'In built-up areas']\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Region of agglomeration')\n",
    "\n",
    "# light conditions for the accidents\n",
    "event_counts = df['lum'].value_counts()\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(1, 5, 3)\n",
    "event_percentages.plot.bar()\n",
    "labels = ['Full day', 'Twilight or dawn', 'Night without public lighting', 'Night with public lighting not lit', 'Night with public lighting on','misinformation']\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Light conditions')\n",
    "\n",
    "# place of accident\n",
    "event_counts = df['int'].value_counts()\n",
    "labels = ['Out of intersection', 'Intersection in X', 'Intersection in T', 'Intersection in Y', 'Intersection with more than 4 branches',\n",
    "        ' Giratory','Place' , 'Level crossing','Other intersection',' unknow', 'error']\n",
    "\n",
    "# Add labels and title to the plot\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(1, 5, 2)\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Intersection')\n",
    "\n",
    "\n",
    "# weather conditions\n",
    "event_counts = df['atm'].value_counts().sort_index()\n",
    "labels = ['Normal', 'Light rain', 'Heavy Rain', 'Snow hail', 'Fog - Smoke','Strong wind- storm','Dazzling weather' , 'Cloudy weather',\n",
    "          'Other ', 'error']\n",
    "\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "plt.subplot(1, 5, 4)\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Weather conditions')\n",
    "\n",
    "# type of road \n",
    "event_counts = df['catr'].value_counts()\n",
    "\n",
    "# Plot the event counts\n",
    "plt.subplot(1, 5, 5)\n",
    "labels = ['Highway', 'National road', 'Departamental road', 'Comunal way', 'OFF public network','Parking lot ', 'Public','other']\n",
    "\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Type of Road')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.subplots_adjust(wspace=0.5, hspace=1.5)\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# surface conditions\n",
    "event_counts = df['surf'].value_counts()\n",
    "\n",
    "# Plot the event counts\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.tight_layout(w_pad=3.0)\n",
    "labels = ['Normal', 'Wet', 'puddles', 'flooded', 'snow','mud','icy', 'fat-oil', 'Other ', 'error1','error2']\n",
    "# Add labels and title to the plot\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Surface condition')\n",
    "\n",
    "# infrastrucutre\n",
    "event_counts = df['infra'].value_counts()\n",
    "\n",
    "# Plot the event counts\n",
    "plt.subplot(1, 5, 2)\n",
    "labels = ['Underground _tunnel', 'Bridge', 'Exchanger or connectionbrace', 'Railway', 'carrefour arranged','Pedestrian','toll zone', 'error1','error2', 'error3','error4']\n",
    "# Add labels and title to the plot\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Infrastructure')\n",
    "\n",
    "# plce of accident \n",
    "event_counts = df['situ'].value_counts()\n",
    "\n",
    "# Plot the event counts\n",
    "plt.subplot(1, 5, 3)\n",
    "labels = ['on the road', 'on emergency stop band', 'on the verge', 'on the sidewalk', 'on bike path', 'error1','error2', 'error3','error4']\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Place of the accident')\n",
    "\n",
    "# colisiion conditions\n",
    "event_counts = df['col'].value_counts()\n",
    "\n",
    "# Plot the event counts\n",
    "plt.subplot(1, 5, 4)\n",
    "labels = ['2 Frontal', '2 Rear', '2 by side', '3 or more chain', '3 + multiple colisions','others', 'without collision','error']\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Colision conditions')\n",
    "\n",
    "# direction of the accident \n",
    "event_counts = df['circ'].value_counts()\n",
    "\n",
    "# Plot the event counts\n",
    "plt.subplot(1, 5, 5)\n",
    "labels = ['One way', 'Bidirectional', 'separeted carriageways', 'with variable assigment channels', 'error','error 2']\n",
    "# Add labels and title to the plot\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar()\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Traffic direction')\n",
    "\n",
    "# plot show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ff5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "# number of accidents per year\n",
    "event_counts = df['an'].value_counts().sort_index()\n",
    "plt.subplot(1,3,1)\n",
    "plt.tight_layout(w_pad=6.0)\n",
    "# Plot the event counts\n",
    "event_counts.plot.bar()\n",
    "plt.xlabel('years')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of accidents per year')\n",
    "\n",
    "#number of accidents per month\n",
    "event_counts = df['mois'].value_counts().sort_index()\n",
    "plt.subplot(1,3,2)\n",
    "# Plot the event counts\n",
    "event_counts.plot.bar()\n",
    "plt.xlabel('months')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of accidents per months')\n",
    "\n",
    "#accidents per day of the month\n",
    "event_counts = df['jour'].value_counts().sort_index()\n",
    "plt.subplot(1,3,3)\n",
    "# Plot the event counts\n",
    "event_counts.plot.bar()\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of accidents per day')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39688a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of accidents per gender\n",
    "\n",
    "event_counts = df['sexe'].value_counts()\n",
    "event_percentages = (event_counts / event_counts.sum()) * 100\n",
    "event_percentages.plot.bar() \n",
    "labels = ['Male', 'Female', 'unknow']\n",
    "# Add labels and title to the plot\n",
    "plt.xticks(range(len(event_percentages)), labels)\n",
    "#plt.xlabel('Events')\n",
    "plt.ylabel('Count %')\n",
    "plt.title('Percentage of accidents per gender')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833150ba-eb13-4b61-aeec-589e6b99c7de",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "### Drop non-metropolitan departments\n",
    "It was decided to use only accidents in metropolitan France and Corse.\n",
    "\n",
    "In preprocessing, the varible `metropolitan` with values `[0,1]` was created.\n",
    "\n",
    "Now, the data is fitered by this variable and then it is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d6d5d-dbec-44dd-bc9f-bdbcbad25f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['metropolitan'] == 1]\n",
    "df.drop('metropolitan', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f85f48-7ffb-4efc-9a0b-afdb9c30f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['adr', 'lat', 'long']\n",
    "df.drop(drop_columns, inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41658d34-2d20-42b3-a328-8caf62e39c75",
   "metadata": {},
   "source": [
    "### Clean gravity\n",
    "Gravity still contains data expressed by `-1` which is related to unknown injury. We need to remove this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3bf9e-1565-4cac-b707-f8e6c7a7d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_count = (df['grav'] == -1).sum()\n",
    "\n",
    "# Print the count\n",
    "print(f\"Number of data points with the value -1 in the 'grav' variable: {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a8ccb-ec82-48c0-a7d8-22d998c2bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['grav'] != -1]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1aee4-69e1-4e86-97f2-e6e1bc2abd7b",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "For the first trial, use the `LabelEncoder` to encode categorial values. Then drop the old categorial values and replace them by the encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec02c2-52f8-47ff-b671-18885e3e4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding with LabelEncoder\n",
    "encode_columns = ['actp', 'num_veh', 'etatp']\n",
    "encoded_df = df[encode_columns]\n",
    "encoded_df = encoded_df.astype('str')\n",
    "encoded_df = encoded_df.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Merge encoded values\n",
    "df.drop(encode_columns, inplace=True, axis=1)\n",
    "df = pd.concat([df, encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of accidents per department \n",
    "\n",
    "department_mapping = {\n",
    "    'Ain': 1, 'Aisne': 2, 'Allier': 3, 'Alpes-de-Haute-Provence': 4, 'Hautes-Alpes': 5,\n",
    "    'Alpes-Maritimes': 6, 'ArdÃ¨che': 7, 'Ardennes': 8, 'AriÃ¨ge': 9, 'Aube': 10,\n",
    "    'Aude': 11, 'Aveyron': 12, 'Bouches-du-RhÃ´ne': 13, 'Calvados': 14, 'Cantal': 15,\n",
    "    'Charente': 16, 'Charente-Maritime': 17, 'Cher': 18, 'CorrÃ¨ze': 19,\n",
    "    '2A Cor(Ajaccio)(Bastia)': 20, 'CÃ´te dDOr': 21,\n",
    "    'CÃ´tes dArmor': 22, 'Creuse': 23, 'Dordogne': 24, 'Doubs': 25, 'DrÃ´me': 26,\n",
    "    'Eure': 27, 'Eure-et-Loir': 28, 'FinistÃ¨re': 29, 'Gard': 30, 'Haute-Garonne': 31,\n",
    "    'Gers': 32, 'Gironde': 33, 'HÃ©rault': 34, 'Ille-et-Vilaine': 35, 'Indre': 36,\n",
    "    'Indre-et-Loire': 37, 'IsÃ¨re': 38, 'Jura': 39, ' Landes': 40, 'Loir-et-Cher': 41,\n",
    "    'Loire': 42, 'Haute-Loire': 43, 'Loire-Atlantique': 44, 'Loiret': 45, 'Lot': 46,\n",
    "    'Lot-et-Garonne': 47, 'LozÃ¨re': 48, 'Maine-et-Loire': 49, 'Manche': 50, 'Marne': 51,\n",
    "    'Haute-Marne': 52, 'Mayenne': 53, 'Moselle': 54, 'Meuse': 55, 'Morbihan': 56,\n",
    "    'Meurthe-et-Moselle': 57, 'NiÃ¨vre': 58, 'Nord': 59, 'Oise': 60, 'Orne': 61,\n",
    "    'Pas-de-Calais': 62, 'Puy-de-DÃ´me': 63, 'PyrÃ©nÃ©es-Atlantiques': 64,\n",
    "    'Hautes-PyrÃ©nÃ©es': 65, 'PyrÃ©nÃ©es Orientales': 66, 'Bas-Rhin': 67, 'Haut-Rhin': 68,\n",
    "    'RhÃ´ne': 69, 'Haute-SaÃ´ne': 70, 'SaÃ´ne-et-Loire': 71, 'Sarthe': 72, 'Savoie': 73,\n",
    "    'Haute-Savoie': 74, 'Paris': 75, 'Seine-Maritime': 76, 'Seine-et-Marne': 77,\n",
    "    'Yvelines': 78, 'Deux-SÃ¨vres': 79, 'Somme': 80, 'Tarn': 81, 'Tarn-et-Garonne': 82,\n",
    "    'Var': 83, 'Vaucluse': 84, 'VendÃ©e': 85, 'Vienne': 86, 'Haute-Vienne': 87,\n",
    "    'Vosges': 88, 'Yonne': 89, 'Territoire de Belfort': 90, 'Essonne': 91,\n",
    "    'Hauts-de-Seine': 92, 'Seine-Saint-Denis': 93, 'Val-de-Marne': 94, 'Val-d\\'Oise': 95\n",
    "}\n",
    "# Reverse the department_mapping dictionary to map department numbers to names\n",
    "department_mapping_reverse = {v: k for k, v in department_mapping.items()}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "event_counts = df['dep'].value_counts()\n",
    "acci_departments = event_counts.sort_values(ascending=False)\n",
    "\n",
    "# Map department codes to department names for the x-axis labels\n",
    "mapped_labels = [department_mapping_reverse.get(dep_code, dep_code) for dep_code in acci_departments.index]\n",
    "\n",
    "# Plot the severity distribution\n",
    "plt.figure(figsize=(18, 8))\n",
    "ax = acci_departments.plot(kind='bar')\n",
    "ax.set_xlabel('Department')\n",
    "ax.set_ylabel('Number of  Cases')\n",
    "ax.set_title(' Cases by Department')\n",
    "ax.set_xticks(range(len(mapped_labels)))\n",
    "ax.set_xticklabels(mapped_labels, rotation=90)\n",
    "\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868aad7-5e7e-4d18-86dd-f4ee01eb6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'datetime' column to a datetime data type\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Extract the weekday from the 'datetime' column\n",
    "df['day_of_week'] = df['datetime'].dt.weekday\n",
    "\n",
    "# Plot the distribution of road traffic accidents by the hour of the day\n",
    "df['day_of_week'].plot(kind='hist', bins=7, edgecolor='k')\n",
    "plt.xlabel('Day of week')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Road Traffic Accidents by day of week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd866a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'datetime' column to a datetime data type\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Extract the hour of the day from the 'datetime' column\n",
    "df['hour_of_day'] = df['datetime'].dt.hour\n",
    "\n",
    "# Plot the distribution of road traffic accidents by the hour of the day\n",
    "df['hour_of_day'].plot(kind='hist', bins=24, edgecolor='k')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Road Traffic Accidents by Hour of Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351aa43-a668-4e56-8e60-495209c131a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/231030_clean_table_for_analysis.csv\", sep = ',', header = True, na_rep = 'n/a', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
